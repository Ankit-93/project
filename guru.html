<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Projects</title>

    <!-- Google Fonts -->
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;700&display=swap" rel="stylesheet">

    <!-- Font Awesome Icons -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">

    <!-- MathJax for Equations -->
    <script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
        </script>

    <style>
        /* Global Styles */
        body {
            font-family: 'Courier New', monospace;
            margin: 0;
            padding: 0;
            color: #ffffff;
            background: url('/assets/images/ml-Background.jpg') no-repeat center center fixed;
            background-size: cover;
            position: relative;
        }

        /* Dark Overlay */
        body::before {
            content: "";
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            background: rgba(0, 0, 0, 0.5);
            z-index: -1;
        }

        /* Layout Containers */
        header,
        footer {
            background: linear-gradient(135deg, #0829df, #04013c);
            text-align: center;
            padding: 20px;
            font-size: 24px;
            position: relative;
            z-index: 10;
        }

        main {
            max-width: 900px;
            margin: 40px auto;
            padding: 25px;
            background: rgba(19, 50, 185, 0.85);
            border-radius: 10px;
            box-shadow: 0px 5px 10px rgba(0, 0, 0, 0.2);
            position: relative;
            z-index: 10;
        }

        h1,
        h2,
        h3 {
            color: #d9dcdf;
        }

        /* Styling for Key Sections */
        .case h3 {
            color: #ffcc00;
        }

        .case p {
            color: #ffffff;
        }

        /* Table Styles */
        table {
            font-family: 'Courier New', monospace;
            width: 100%;
            border-collapse: collapse;
            margin: 10px 0;
            background: rgba(255, 255, 255, 0.1);
        }

        th,
        td {
            border: 1px solid #ccc;
            padding: 8px;
            text-align: center;
            font-size: 14px;
        }

        th {
            background: rgba(0, 0, 0, 0.2);
        }

        /* Image Styling */
        .image-container {
            text-align: center;
            margin: 10px 0;
        }

        .image-container img {
            width: 35%;
            border-radius: 5px;
            box-shadow: 0px 5px 10px rgba(0, 0, 0, 0.2);
        }

        /* Content Alignment */
        .content-container {
            display: flex;
            align-items: center;
            justify-content: space-between;
            gap: 10px;
        }

        .image-container {
            flex: 1;
        }

        .image-container img {
            width: 65%;
            border-radius: 10px;
        }

        .text-container {
            flex: 1;
            width: 55%;
        }

        /* Failure Cases Section */
        .failure-cases {
            width: 90%;
            max-width: 1600px;
            background: rgba(255, 255, 255, 0.1);
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0px 5px 10px rgba(0, 0, 0, 0.2);
            margin: 20px auto;
            text-align: justify;
        }

        .case {
            width: 100%;
            background: rgba(255, 255, 255, 0.15);
            padding: 15px;
            margin-bottom: 15px;
            border-radius: 6px;
        }

        /* Decision Tree Node Styles */
        .node circle {
            fill: #69b3a2;
            stroke: #555;
            stroke-width: 2px;
        }

        .node text {
            font-size: 14px;
            font-family: 'Courier New', monospace;
            fill: white;
        }

        .link {
            fill: none;
            stroke: #ccc;
            stroke-width: 2px;
        }

        * {
            user-select: text;
        }
    </style>
</head>

<header>
    <h1>Building an AI-Powered Knowledge Repository and Search Engine for Enterprise
        Code and Documents</h1>
</header>

<body>

    <div class="failure-cases">
        <div class="case">
            <html>
                <head>
                    <title>AI-Powered Knowledge Repository</title>
                </head>
                <body>
                    <h1>AI-Powered Knowledge Repository and Search Engine for Enterprise Code and Documents</h1>
                    
                    <h2>Project Overview</h2>
                    <p>This project aims to build a centralized repository for enterprise code and documents, enabling efficient search and retrieval using AI-powered semantic understanding and analysis. By leveraging AI/ML techniques such as Natural Language Processing (NLP), Optical Character Recognition (OCR), and machine learning models for classification and entity recognition, the system enhances document accessibility and organization.</p>
                    
                    <h2>Key Components and Functionality</h2>
                    <h3>Data Ingestion and Processing</h3>
                    <ul>
                        <li><b>Crawler & Delta:</b> Collects documents from various sources like SharePoint and S3 buckets, focusing on incremental updates and changes.</li>
                        <li><b>Nightly Document Delta Job Scheduler:</b> Automates the crawling and updating process.</li>
                        <li><b>SOT Doc Pipeline & Delta:</b> Processes ingested documents, including format conversion, metadata extraction, and text preprocessing.</li>
                        <li><b>Data Extraction/OCR:</b> Utilizes Textract and openpyxl for extracting text, including OCR for scanned documents.</li>
                        <li><b>Snippet Creation:</b> Breaks down documents into smaller, searchable chunks.</li>
                    </ul>
                    
                    <h3>AI-Driven Understanding and Enrichment</h3>
                    <ul>
                        <li><b>Document Classification:</b> Uses deep learning and traditional ML models to categorize documents for better organization and retrieval.</li>
                        <li><b>Custom Named Entity Recognition (NER):</b> Extracts key entities (e.g., people, organizations, locations) to enrich metadata.</li>
                        <li><b>Recognize Entities:</b> Identifies domain-specific entities for improved searchability.</li>
                        <li><b>Large Language Model (LLM) Integration:</b> Enhances semantic understanding, calculates coverage and limits, and refines the "Source of Truth" (SOT) data model.</li>
                        <li><b>Classification/Semantic Model (FAISS):</b> Implements FAISS for similarity search and document clustering based on semantic meaning.</li>
                    </ul>
                    
                    <h3>Data Storage and Management</h3>
                    <ul>
                        <li><b>EFS (Elastic File System):</b> Temporary storage during processing.</li>
                        <li><b>MongoDB (Metadata Storage):</b> Stores document metadata and revision history.</li>
                        <li><b>S3 Bucket (Documents):</b> Stores actual document files.</li>
                        <li><b>Knowledge Graph (MongoDB):</b> Captures relationships between entities and concepts.</li>
                        <li><b>Facets Data Model (MongoDB):</b> Stores facets (categories/filters) for navigation.</li>
                        <li><b>MySQL Aurora (Facets Staging):</b> Staging database for facets before finalization.</li>
                    </ul>
                    
                    <h3>Search and Retrieval</h3>
                    <ul>
                        <li><b>Amazon Kendra:</b> Provides enterprise search with indexing capabilities.</li>
                        <li><b>Search Engine (UI & APIs):</b> Interfaces for user interaction.</li>
                        <li><b>Facets Code, Coverage, Limits:</b> Enhances filtering of search results.</li>
                        <li><b>Mapping Engine:</b> Maps search queries to relevant documents and concepts in the knowledge graph.</li>
                    </ul>
                    
                    <h3>User Interface and Access</h3>
                    <ul>
                        <li><b>Users (GURU UI):</b> Dedicated UI for searching documents, code snippets, and information.</li>
                    </ul>
                    
                    <h2>AI/ML Contributions</h2>
                    <h3>Named Entity Recognition (NER)</h3>
                    <p>I developed an NER model to extract entities such as people, organizations, and locations from documents. This involved fine-tuning models like spaCy with domain-specific data to improve accuracy. The model was integrated into the broader pipeline to tag documents with entities, enabling advanced search functionalities.</p>
                    
                    <h3>Document Classification</h3>
                    <p>I implemented classification models using deep learning techniques, including LSTM and BERT, to categorize documents accurately based on content. Fine-tuning BERT on enterprise data improved its generalization and accuracy in document classification.</p>
                    
                    <h3>Semantic Search & Knowledge Graph Construction</h3>
                    <p>By leveraging LLMs and FAISS, I contributed to improving the search experience by focusing on query meaning rather than just keywords. I also helped build a knowledge graph that captured entity relationships, enhancing search relevance.</p>
                    
                    <h2>Challenges and Solutions</h2>
                    <ul>
                        <li><b>Data Quality:</b> Worked with data engineers to clean and preprocess data, improving model performance.</li>
                        <li><b>Model Generalization:</b> Used transfer learning to fine-tune models for diverse enterprise documents.</li>
                        <li><b>Scalability:</b> Optimized AI models and collaborated with the infrastructure team to ensure efficient processing of large document volumes.</li>
                    </ul>
                    
                    <h2>Impact and Results</h2>
                    <p>My contributions to NER and document classification significantly improved the system's search accuracy and efficiency. The AI-powered search engine enhanced semantic understanding, leading to better user satisfaction and streamlined document retrieval. This project successfully built a robust, AI-driven knowledge management system, making enterprise information assets more accessible and valuable.</p>
                </body>
                </html>
                
                
        </div>
    </div>

</body>

</html>